{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RL Project"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-07T19:19:54.495811Z",
     "start_time": "2021-12-07T19:19:54.127857Z"
    }
   },
   "outputs": [],
   "source": [
    "# imports\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.colors as mcolors\n",
    "import matplotlib.patches as mpatches\n",
    "from enum import IntEnum"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Environment & MDP methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-07T23:36:09.433147Z",
     "start_time": "2021-12-07T23:36:09.357342Z"
    }
   },
   "outputs": [],
   "source": [
    "class Action(IntEnum):\n",
    "    STAY = 0\n",
    "    UP = 1\n",
    "    DOWN = 2\n",
    "    LEFT = 3\n",
    "    RIGHT = 4\n",
    "\n",
    "class MDP:\n",
    "    \n",
    "    # How to use :\n",
    "    #\n",
    "    # Use mdp.call(state, action) to get info on the environment.\n",
    "    # --> Do NOT use T & R matrices to get info on the environnement.\n",
    "    # --> You CAN use mdp.utils methods, as long as it has a update_n_calls parameter.\n",
    "    # Use mdp.step(action) to move the agent .\n",
    "    # Use mdp.V to store & update state values.\n",
    "    # Use mdp.n_calls to get the number of calls made to the environnement.\n",
    "    # Use mdp.reset() when the episode has ended to start over.\n",
    "\n",
    "    def __init__(self, N = 5, discount_factor = 0.97, reward_range = 0.1):\n",
    "        self.N = N\n",
    "        self.n_states = N * N\n",
    "        self.discount_factor = discount_factor\n",
    "        self.reward_range = reward_range\n",
    "        self.reset()\n",
    "        self.T = self.generate_transition_matrix(N)\n",
    "        self.displayer = MDP_Displayer(self)\n",
    "        self.utils = MDP_Utils(self)\n",
    "    \n",
    "    def generate_transition_matrix(self, N):\n",
    "        transition_matrix = np.zeros((N * N, len(Action)), dtype=int)\n",
    "        for s, state in enumerate(transition_matrix):\n",
    "            state[Action.UP] = s - N if s >= N else s\n",
    "            state[Action.DOWN] = s + N if s < N * N - N else s\n",
    "            state[Action.LEFT] = s - 1 if s % N else s\n",
    "            state[Action.RIGHT] = s + 1 if (s + 1) % N else s\n",
    "            state[Action.STAY] = s\n",
    "        return transition_matrix\n",
    "    \n",
    "    def generate_rewards(self, N, reward_range):\n",
    "        rewards = np.random.uniform(-reward_range, reward_range, N * N)\n",
    "        rewards[np.random.randint(0, N * N)] = 1\n",
    "        return rewards\n",
    "    \n",
    "    def generate_state_values(self, N):\n",
    "        return np.random.normal(size = N * N)\n",
    "    \n",
    "    def reset(self):\n",
    "        self.n_calls = 0\n",
    "        self.state = 0 # Paper does no mention what state to start on: 0 or random ?\n",
    "        self.R = self.generate_rewards(self.N, self.reward_range)\n",
    "        self.V = self.generate_state_values(self.N)\n",
    "    \n",
    "    def step(self, action):\n",
    "        self.state = self.T[self.state, action]\n",
    "        return self.state, self.R[self.state]\n",
    "    \n",
    "    def call(self, state, action):\n",
    "        n_calls += 1\n",
    "        new_state = self.T[state, action]\n",
    "        return new_state, self.R[new_state]\n",
    "        \n",
    "class MDP_Displayer:\n",
    "    \n",
    "    def __init__(self, mdp):\n",
    "        self.mdp = mdp\n",
    "        self.set_action_colors()\n",
    "    \n",
    "    def display_rewards(self, numerical = False, colorbar = True, ticks = False, title = \"Rewards\"):\n",
    "        self.display_heatmap(self.mdp.R, numerical, colorbar, ticks, title)\n",
    "    \n",
    "    def display_state_values(self, numerical = False, colorbar = True, ticks = False, title = \"State values\"):\n",
    "        self.display_heatmap(self.mdp.V, numerical, colorbar, ticks, title)\n",
    "        \n",
    "    def display_actions_based_on_rewards(self, ticks = False, title = \"Best actions based on rewards\"):\n",
    "        self.display_actions(self.mdp.utils.get_best_actions_based_on_rewards(False), ticks, title)\n",
    "    \n",
    "    def display_actions_based_on_state_values(self, ticks = False, title = \"Best actions based on state values\"):\n",
    "        self.display_actions(self.mdp.utils.get_best_actions_based_on_state_values(), ticks, title)\n",
    "    \n",
    "    def display_heatmap(self, array, numerical = False, colorbar = True, ticks = False, title = \"Heatmap\"):\n",
    "        data = np.reshape(array, (self.mdp.N, self.mdp.N))\n",
    "        if not ticks: self.remove_ticks()\n",
    "        if numerical: self.add_numerical(data)\n",
    "        plt.imshow(data)\n",
    "        plt.title(title)\n",
    "        if colorbar: plt.colorbar()\n",
    "        plt.show()\n",
    "        \n",
    "    def display_actions(self, actions, ticks = False, title = \"Actions\"):  \n",
    "        self.add_action_legend()\n",
    "        data = np.reshape(actions, (self.mdp.N, self.mdp.N))\n",
    "        if not ticks: self.remove_ticks()\n",
    "        plt.imshow(data, cmap = self.action_cmap, norm = self.action_norm)\n",
    "        plt.title(title)\n",
    "        plt.show()\n",
    "    \n",
    "    def remove_ticks(self):\n",
    "        plt.gca().set_xticklabels([])\n",
    "        plt.gca().set_yticklabels([])\n",
    "        for tick in plt.gca().xaxis.get_major_ticks():\n",
    "            tick.tick1line.set_visible(False)\n",
    "            tick.tick2line.set_visible(False)\n",
    "        for tick in plt.gca().yaxis.get_major_ticks():\n",
    "            tick.tick1line.set_visible(False)\n",
    "            tick.tick2line.set_visible(False)\n",
    "    \n",
    "    # Adds numerical data inside each cell of the plot\n",
    "    def add_numerical(self, data):\n",
    "        image = plt.imshow(data)\n",
    "        threshold = image.norm(data.max()) * 2/3\n",
    "        for i in range(len(data)):\n",
    "            for j in range(len(data[i])):\n",
    "                color = int(image.norm(data[i, j]) < threshold)\n",
    "                text = plt.gca().text(j, i, round(data[i, j], 2),\n",
    "                                      ha = \"center\", va = \"center\", color = str(color))\n",
    "    \n",
    "    def add_action_legend(self):\n",
    "        handles = []\n",
    "        for i, action in enumerate(Action):\n",
    "            handles.append(mpatches.Patch(color = self.action_colors[i],\n",
    "                                          label = str(action)[str(action).find(\".\") + 1:]))\n",
    "        plt.legend(title=\"Actions\", handles = handles, loc='upper left', bbox_to_anchor=(1, 1))\n",
    "        \n",
    "    def set_action_colors(self):\n",
    "        self.action_colors = [\"purple\", \"red\", \"blue\", \"green\", \"yellow\"]\n",
    "        self.action_cmap = mcolors.ListedColormap(self.action_colors)\n",
    "        self.action_norm = mcolors.BoundaryNorm(list(range(len(Action) + 1)), self.action_cmap.N)\n",
    "        \n",
    "class MDP_Utils:\n",
    "    \n",
    "    def __init__(self, mdp):\n",
    "        self.mdp = mdp\n",
    "        \n",
    "    # GENERATIVE METHODS ========================================================================\n",
    "        \n",
    "    # Warning: depth > 9 will most likely crash your kernel\n",
    "    def get_action_trajecories(self, depth):\n",
    "        return np.array(np.meshgrid(*[Action] * depth)).T.reshape(-1, depth)\n",
    "    \n",
    "    def get_uniform_policy(self):\n",
    "        return np.ones((self.mdp.n_states, len(Action)), dtype=int) / len(Action)\n",
    "    \n",
    "    def get_greedy_policy(self):\n",
    "        return self.actions_to_greedy_policy(self.get_best_actions_based_on_rewards())\n",
    "        \n",
    "    # INFORMATIVE METHODS =======================================================================\n",
    "    \n",
    "    def get_best_actions_based_on_rewards(self, update_n_calls = True):\n",
    "        return np.argmax(self.get_action_rewards(update_n_calls), 1)\n",
    "    \n",
    "    def get_best_actions_based_on_state_values(self):\n",
    "        return np.argmax(self.get_action_state_values(), 1)   \n",
    "    \n",
    "    # Return rewards array of size (n_state, actions)\n",
    "    def get_action_rewards(self, update_n_calls = True):\n",
    "        action_rewards = self.mdp.R[self.mdp.T]\n",
    "        if update_n_calls: self.mdp.n_calls += self.mdp.n_states * len(Action)\n",
    "        return action_rewards\n",
    "    \n",
    "    # Return state values array of size (n_state, actions), aka the value of the next state\n",
    "    def get_action_state_values(self):\n",
    "        action_state_values = self.mdp.V[self.mdp.T]\n",
    "        return action_state_values\n",
    "    \n",
    "    # CONVERSION METHODS ========================================================================\n",
    "        \n",
    "    def actions_to_greedy_policy(self, best_actions):\n",
    "        return np.eye(len(Action))[best_actions]\n",
    "    \n",
    "    def greedy_policy_to_actions(self, policy):\n",
    "        return np.argmax(policy, 1)\n",
    "    \n",
    "    # top_left=(0,0) any_coord=(row, column)\n",
    "    def state_to_coord(self, state):\n",
    "        return (int(np.floor(state / self.mdp.N)), state % self.mdp.N)\n",
    "    \n",
    "    # top_left=(0,0) any_coord=(row, column)\n",
    "    def coord_to_state(self, coord):\n",
    "        return coord[0] * self.mdp.N + coord[1]\n",
    "    \n",
    "    # BELLMAN METHODS =====================================================================\n",
    "    #\n",
    "    # check out this link for a better explanation of R, P, V & T than the paper's\n",
    "    # https://ai.stackexchange.com/questions/11057/what-is-the-bellman-operator-in-reinforcement-learning\n",
    "    #\n",
    "    # All the R, P = None is to make sure all functions can be called in a loop without recomputing R, P\n",
    "    # Same thing for returning R, P\n",
    "    \n",
    "    # Corresponds to bellman's P^π in the paper\n",
    "    def get_bellman_transition_kernel(self, policy):\n",
    "        P = np.zeros((self.mdp.n_states, self.mdp.n_states))\n",
    "        for s, state_transition in enumerate(self.mdp.T):\n",
    "            for action in Action:\n",
    "                P[s, state_transition[action]] += policy[s, action] # Should we update n_calls?\n",
    "        return P\n",
    "    \n",
    "    # Corresponds to bellman's r^π in the paper\n",
    "    def get_bellman_rewards(self, policy, update_n_calls = True):\n",
    "        self.mdp.n_calls += self.mdp.n_states * len(Action)\n",
    "        return np.sum(self.mdp.R[self.mdp.T] * policy, 1)\n",
    "    \n",
    "    # Corresponds to T^π in the paper\n",
    "    def bellman_operator(self, R = None, P = None, V = None, policy = None, update_n_calls = True):\n",
    "        if policy is None: policy = self.get_uniform_policy()\n",
    "        if R is None: R = self.get_bellman_rewards(policy, update_n_calls)\n",
    "        if P is None: P = self.get_bellman_transition_kernel(policy)\n",
    "        if V is None: V = self.mdp.V\n",
    "        V = R + self.mdp.discount_factor * P.dot(V)\n",
    "        return R, P, V\n",
    "    \n",
    "    # Corresponds to T & T_x in the paper\n",
    "    # Used equivalent of T* in https://ai.stackexchange.com/questions/11057/what-is-the-bellman-operator-in-reinforcement-learning\n",
    "    def bellman_optimatlity_operator(self, R = None, P = None, V = None, policy = None, update_n_calls = True):\n",
    "        if V is None: V = mdp.V\n",
    "        self.mdp.n_calls += self.mdp.n_states * len(Action)\n",
    "        V = np.max(mdp.R[mdp.T] + self.mdp.discount_factor * V[mdp.T], 1) # V[mdp.T] is the same as P^a * v\n",
    "        return V\n",
    "    \n",
    "    # Corresponds to G & G_h in the paper\n",
    "    def get_h_greedy_policy(self, h = 1, R = None, P = None, V = None, policy = None, update_n_calls = True):\n",
    "        for i in range(h - 1):\n",
    "            V = self.bellman_optimatlity_operator(R, P, V, policy, update_n_calls)\n",
    "        R, P, V = self.bellman_operator(R, P, V, policy, update_n_calls)\n",
    "        best_actions = np.argmax(V[mdp.T], 1)\n",
    "        policy = self.actions_to_greedy_policy(best_actions)\n",
    "        return policy, V\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Algorithms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-07T23:36:42.646187Z",
     "start_time": "2021-12-07T23:36:42.598993Z"
    }
   },
   "outputs": [],
   "source": [
    "tolerance = 1e-7\n",
    "\n",
    "def value_or_policy_iteration(mdp = MDP()):\n",
    "    pass\n",
    "\n",
    "def h_PI(mdp, h = 1):\n",
    "    if mdp.discount_factor < 0 or mdp.discount_factor >= 1:\n",
    "        raise ValueError(\"h_PI() will not converge unless discount_factor ∈ [0, 1[\")\n",
    "    V = mdp.V\n",
    "    while True:\n",
    "        policy, V = mdp.utils.get_h_greedy_policy(h = h, V = V)\n",
    "        if np.allclose(Vs[-1], Vs[-2], tolerance): break\n",
    "    return policy, V\n",
    "\n",
    "def NC_hm_PI(mdp, h = 1, m = 1):\n",
    "    pass\n",
    "\n",
    "def hm_PI(mdp, h = 1, m = 1):\n",
    "    pass\n",
    "\n",
    "def NC_hλ_PI(mdp, h = 1, λ = 1):\n",
    "    pass\n",
    "\n",
    "def hλ_PI(mdp, h = 1, λ = 1):\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Experiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-07T23:39:39.152992Z",
     "start_time": "2021-12-07T23:39:38.676184Z"
    }
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# h_PI example\n",
    "mdp = MDP(N = 10)\n",
    "policy, V = h_PI(mdp, h = 30)\n",
    "mdp.displayer.display_rewards(title = \"MDP's rewards\")\n",
    "mdp.displayer.display_actions(mdp.utils.greedy_policy_to_actions(policy), title = \"h-greedy's calculated best actions\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
